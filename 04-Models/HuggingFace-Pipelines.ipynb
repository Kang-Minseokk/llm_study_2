{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T14:17:09.902496Z",
     "start_time": "2024-09-26T14:17:07.225399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "!pip install -qU transformers\n",
    "!pip install langchain-core==0.2.38\n",
    "!pip install --upgrade langchain-huggingface"
   ],
   "id": "e25d30086a06cc47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-core==0.2.38\r\n",
      "  Using cached langchain_core-0.2.38-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langchain-core==0.2.38) (6.0.2)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langchain-core==0.2.38) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langchain-core==0.2.38) (0.1.128)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langchain-core==0.2.38) (23.2)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langchain-core==0.2.38) (2.8.2)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langchain-core==0.2.38) (8.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langchain-core==0.2.38) (4.12.2)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.2.38) (3.0.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core==0.2.38) (0.27.0)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core==0.2.38) (3.10.7)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core==0.2.38) (2.32.3)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core==0.2.38) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core==0.2.38) (2.20.1)\r\n",
      "Requirement already satisfied: anyio in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core==0.2.38) (4.4.0)\r\n",
      "Requirement already satisfied: certifi in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core==0.2.38) (2024.7.4)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core==0.2.38) (1.0.5)\r\n",
      "Requirement already satisfied: idna in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core==0.2.38) (3.7)\r\n",
      "Requirement already satisfied: sniffio in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core==0.2.38) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core==0.2.38) (0.14.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core==0.2.38) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core==0.2.38) (2.2.2)\r\n",
      "Using cached langchain_core-0.2.38-py3-none-any.whl (396 kB)\r\n",
      "Installing collected packages: langchain-core\r\n",
      "  Attempting uninstall: langchain-core\r\n",
      "    Found existing installation: langchain-core 0.2.0\r\n",
      "    Uninstalling langchain-core-0.2.0:\r\n",
      "      Successfully uninstalled langchain-core-0.2.0\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "langchain-community 0.2.15 requires langchain<0.3.0,>=0.2.15, but you have langchain 0.3.0 which is incompatible.\r\n",
      "langchain 0.3.0 requires langchain-core<0.4.0,>=0.3.0, but you have langchain-core 0.2.38 which is incompatible.\r\n",
      "langchain-text-splitters 0.3.0 requires langchain-core<0.4.0,>=0.3.0, but you have langchain-core 0.2.38 which is incompatible.\r\n",
      "langchain-google-genai 2.0.0 requires langchain-core<0.4,>=0.3.0, but you have langchain-core 0.2.38 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed langchain-core-0.2.38\r\n",
      "Requirement already satisfied: langchain-huggingface in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (0.0.3)\r\n",
      "Collecting langchain-huggingface\r\n",
      "  Downloading langchain_huggingface-0.1.0-py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langchain-huggingface) (0.24.5)\r\n",
      "Collecting langchain-core<0.4,>=0.3.0 (from langchain-huggingface)\r\n",
      "  Downloading langchain_core-0.3.6-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langchain-huggingface) (3.0.1)\r\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langchain-huggingface) (0.20.0)\r\n",
      "Requirement already satisfied: transformers>=4.39.0 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langchain-huggingface) (4.45.0)\r\n",
      "Requirement already satisfied: filelock in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.15.4)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.6.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\r\n",
      "Requirement already satisfied: requests in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.66.5)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.1.128)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (2.8.2)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (8.5.0)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.4.0)\r\n",
      "Requirement already satisfied: numpy in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.26.4)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.5.1)\r\n",
      "Requirement already satisfied: scipy in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.0)\r\n",
      "Requirement already satisfied: Pillow in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.4.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.7.24)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.4)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-huggingface) (3.0.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.27.0)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (3.10.7)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4,>=0.3.0->langchain-huggingface) (2.20.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.7.4)\r\n",
      "Requirement already satisfied: sympy in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\r\n",
      "Requirement already satisfied: setuptools in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (72.1.0)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\r\n",
      "Requirement already satisfied: anyio in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (4.4.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.0.5)\r\n",
      "Requirement already satisfied: sniffio in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.14.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\r\n",
      "Downloading langchain_huggingface-0.1.0-py3-none-any.whl (20 kB)\r\n",
      "Downloading langchain_core-0.3.6-py3-none-any.whl (399 kB)\r\n",
      "Installing collected packages: langchain-core, langchain-huggingface\r\n",
      "  Attempting uninstall: langchain-core\r\n",
      "    Found existing installation: langchain-core 0.2.38\r\n",
      "    Uninstalling langchain-core-0.2.38:\r\n",
      "      Successfully uninstalled langchain-core-0.2.38\r\n",
      "  Attempting uninstall: langchain-huggingface\r\n",
      "    Found existing installation: langchain-huggingface 0.0.3\r\n",
      "    Uninstalling langchain-huggingface-0.0.3:\r\n",
      "      Successfully uninstalled langchain-huggingface-0.0.3\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "langchain-openai 0.1.22 requires langchain-core<0.3.0,>=0.2.33, but you have langchain-core 0.3.6 which is incompatible.\r\n",
      "langchain-community 0.2.15 requires langchain<0.3.0,>=0.2.15, but you have langchain 0.3.0 which is incompatible.\r\n",
      "langchain-community 0.2.15 requires langchain-core<0.3.0,>=0.2.37, but you have langchain-core 0.3.6 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed langchain-core-0.3.6 langchain-huggingface-0.1.0\r\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-26T14:09:23.603501Z",
     "start_time": "2024-09-26T14:09:23.596442Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T14:17:33.289693Z",
     "start_time": "2024-09-26T14:17:14.027225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from pydantic import BaseModel\n",
    "\n",
    "model_id = \"google/gemma-2-2b-it\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id)\n",
    "\n",
    "pipe = pipeline('text-generation', model=model, tokenizer=tokenizer, max_new_tokens=512, device='auto')\n",
    "\n",
    "hf = HuggingFacePipeline(pipeline=pipe)\n"
   ],
   "id": "9879f32db9aba2a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0925e05c018e4f4a9ff52c6c8637342d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T14:23:34.536869Z",
     "start_time": "2024-09-26T14:23:34.530990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "login(token=os.environ.get('HF_TOKEN'))"
   ],
   "id": "39984e6368b8d008",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b97bba83a424de08faa7e10c32d68bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T14:24:18.968321Z",
     "start_time": "2024-09-26T14:24:15.053719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_huggingface import ChatHuggingFace\n",
    "llm = ChatHuggingFace(llm=hf)"
   ],
   "id": "627c95e1764601ff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1295a91b08964d4397be6c464762d321"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5439b10f38a942db8c2bb3726868524b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0198813e6404af3a499d41a30b2ca98"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "976b3a3a6a244d5b85fafc811ab81767"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e8611fcf1ff47408a75f1e0892e2d32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minseokkang/projects/llm_study/venvs/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T14:24:18.970503Z",
     "start_time": "2024-09-26T14:24:18.969240Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3d943e86b5e0105b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T14:26:25.201495Z",
     "start_time": "2024-09-26T14:26:24.906855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "template = \"\"\"<|system|>You are a helpful assistant.<|end|>\n",
    "<|user|>{question}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "question = \"대한민국의 수도는 어디야?\"\n",
    "\n",
    "answer = chain.stream({\"question\": question})\n",
    "stream_response(answer) "
   ],
   "id": "ddf2fa57c494df71",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 15\u001B[0m\n\u001B[1;32m     12\u001B[0m question \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m대한민국의 수도는 어디야?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     14\u001B[0m answer \u001B[38;5;241m=\u001B[39m chain\u001B[38;5;241m.\u001B[39mstream({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquestion\u001B[39m\u001B[38;5;124m\"\u001B[39m: question})\n\u001B[0;32m---> 15\u001B[0m \u001B[43mstream_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43manswer\u001B[49m\u001B[43m)\u001B[49m \n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_teddynote/messages.py:20\u001B[0m, in \u001B[0;36mstream_response\u001B[0;34m(response, return_output)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03mAI 모델로부터의 응답을 스트리밍하여 각 청크를 처리하면서 출력합니다.\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;124;03m- str: `return_output`이 True인 경우, 연결된 응답 문자열입니다. 그렇지 않으면, 아무것도 반환되지 않습니다.\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     19\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 20\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mAIMessageChunk\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m        \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_core/runnables/base.py:3405\u001B[0m, in \u001B[0;36mRunnableSequence.stream\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   3399\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstream\u001B[39m(\n\u001B[1;32m   3400\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   3401\u001B[0m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[1;32m   3402\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   3403\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   3404\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[0;32m-> 3405\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(\u001B[38;5;28miter\u001B[39m([\u001B[38;5;28minput\u001B[39m]), config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_core/runnables/base.py:3392\u001B[0m, in \u001B[0;36mRunnableSequence.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   3386\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\n\u001B[1;32m   3387\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   3388\u001B[0m     \u001B[38;5;28minput\u001B[39m: Iterator[Input],\n\u001B[1;32m   3389\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   3390\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   3391\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[0;32m-> 3392\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform_stream_with_config(\n\u001B[1;32m   3393\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   3394\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform,\n\u001B[1;32m   3395\u001B[0m         patch_config(config, run_name\u001B[38;5;241m=\u001B[39m(config \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m   3396\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3397\u001B[0m     )\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_core/runnables/base.py:2193\u001B[0m, in \u001B[0;36mRunnable._transform_stream_with_config\u001B[0;34m(self, input, transformer, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   2191\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2192\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 2193\u001B[0m         chunk: Output \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   2194\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m chunk\n\u001B[1;32m   2195\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m final_output_supported:\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_core/runnables/base.py:3355\u001B[0m, in \u001B[0;36mRunnableSequence._transform\u001B[0;34m(self, input, run_manager, config, **kwargs)\u001B[0m\n\u001B[1;32m   3352\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3353\u001B[0m         final_pipeline \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39mtransform(final_pipeline, config)\n\u001B[0;32m-> 3355\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m final_pipeline\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_core/output_parsers/transform.py:64\u001B[0m, in \u001B[0;36mBaseTransformOutputParser.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28minput\u001B[39m: Iterator[Union[\u001B[38;5;28mstr\u001B[39m, BaseMessage]],\n\u001B[1;32m     51\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m     53\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[T]:\n\u001B[1;32m     54\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Transform the input into the output format.\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \n\u001B[1;32m     56\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;124;03m        The transformed output.\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 64\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform_stream_with_config(\n\u001B[1;32m     65\u001B[0m         \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform, config, run_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparser\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     66\u001B[0m     )\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_core/runnables/base.py:2157\u001B[0m, in \u001B[0;36mRunnable._transform_stream_with_config\u001B[0;34m(self, input, transformer, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   2155\u001B[0m input_for_tracing, input_for_transform \u001B[38;5;241m=\u001B[39m tee(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m   2156\u001B[0m \u001B[38;5;66;03m# Start the input iterator to ensure the input Runnable starts before this one\u001B[39;00m\n\u001B[0;32m-> 2157\u001B[0m final_input: Optional[Input] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43minput_for_tracing\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   2158\u001B[0m final_input_supported \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   2159\u001B[0m final_output: Optional[Output] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_core/runnables/base.py:1427\u001B[0m, in \u001B[0;36mRunnable.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   1424\u001B[0m             final \u001B[38;5;241m=\u001B[39m ichunk\n\u001B[1;32m   1426\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m got_first_val:\n\u001B[0;32m-> 1427\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream(final, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:363\u001B[0m, in \u001B[0;36mBaseChatModel.stream\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    352\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstream\u001B[39m(\n\u001B[1;32m    353\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    354\u001B[0m     \u001B[38;5;28minput\u001B[39m: LanguageModelInput,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    358\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    359\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[BaseMessageChunk]:\n\u001B[1;32m    360\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_stream(async_api\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m{\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m}}):\n\u001B[1;32m    361\u001B[0m         \u001B[38;5;66;03m# model doesn't implement streaming, so use default implementation\u001B[39;00m\n\u001B[1;32m    362\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m cast(\n\u001B[0;32m--> 363\u001B[0m             BaseMessageChunk, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    364\u001B[0m         )\n\u001B[1;32m    365\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    366\u001B[0m         config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:284\u001B[0m, in \u001B[0;36mBaseChatModel.invoke\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m    274\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    275\u001B[0m     \u001B[38;5;28minput\u001B[39m: LanguageModelInput,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    279\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    280\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseMessage:\n\u001B[1;32m    281\u001B[0m     config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[1;32m    283\u001B[0m         ChatGeneration,\n\u001B[0;32m--> 284\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m            \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcallbacks\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    288\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtags\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    294\u001B[0m     )\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:784\u001B[0m, in \u001B[0;36mBaseChatModel.generate_prompt\u001B[0;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    776\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[1;32m    777\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    778\u001B[0m     prompts: \u001B[38;5;28mlist\u001B[39m[PromptValue],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    781\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    782\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[1;32m    783\u001B[0m     prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[0;32m--> 784\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:641\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[1;32m    639\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n\u001B[1;32m    640\u001B[0m             run_managers[i]\u001B[38;5;241m.\u001B[39mon_llm_error(e, response\u001B[38;5;241m=\u001B[39mLLMResult(generations\u001B[38;5;241m=\u001B[39m[]))\n\u001B[0;32m--> 641\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    642\u001B[0m flattened_outputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    643\u001B[0m     LLMResult(generations\u001B[38;5;241m=\u001B[39m[res\u001B[38;5;241m.\u001B[39mgenerations], llm_output\u001B[38;5;241m=\u001B[39mres\u001B[38;5;241m.\u001B[39mllm_output)  \u001B[38;5;66;03m# type: ignore[list-item]\u001B[39;00m\n\u001B[1;32m    644\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results\n\u001B[1;32m    645\u001B[0m ]\n\u001B[1;32m    646\u001B[0m llm_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_combine_llm_outputs([res\u001B[38;5;241m.\u001B[39mllm_output \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results])\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:631\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages):\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    630\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 631\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    633\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    634\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    635\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    636\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    637\u001B[0m         )\n\u001B[1;32m    638\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    639\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:853\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    851\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    852\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 853\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    854\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    856\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    857\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_huggingface/chat_models/huggingface.py:373\u001B[0m, in \u001B[0;36mChatHuggingFace._generate\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    371\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_chat_result(answer)\n\u001B[1;32m    372\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 373\u001B[0m     llm_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_to_chat_prompt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    374\u001B[0m     llm_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm\u001B[38;5;241m.\u001B[39m_generate(\n\u001B[1;32m    375\u001B[0m         prompts\u001B[38;5;241m=\u001B[39m[llm_input], stop\u001B[38;5;241m=\u001B[39mstop, run_manager\u001B[38;5;241m=\u001B[39mrun_manager, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    376\u001B[0m     )\n\u001B[1;32m    377\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_to_chat_result(llm_result)\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/langchain_huggingface/chat_models/huggingface.py:410\u001B[0m, in \u001B[0;36mChatHuggingFace._to_chat_prompt\u001B[0;34m(self, messages)\u001B[0m\n\u001B[1;32m    406\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLast message must be a HumanMessage!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    408\u001B[0m messages_dicts \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_to_chatml_format(m) \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m messages]\n\u001B[0;32m--> 410\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_chat_template\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessages_dicts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_generation_prompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m    412\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1809\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.apply_chat_template\u001B[0;34m(self, conversation, tools, documents, chat_template, add_generation_prompt, continue_final_message, tokenize, padding, truncation, max_length, return_tensors, return_dict, return_assistant_tokens_mask, tokenizer_kwargs, **kwargs)\u001B[0m\n\u001B[1;32m   1806\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tokenizer_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1807\u001B[0m     tokenizer_kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m-> 1809\u001B[0m chat_template \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_chat_template\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchat_template\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1811\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_assistant_tokens_mask \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m re\u001B[38;5;241m.\u001B[39msearch(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m-?\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms*generation\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms*-?\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m}\u001B[39m\u001B[38;5;124m\"\u001B[39m, chat_template):\n\u001B[1;32m   1812\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning_once(\n\u001B[1;32m   1813\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreturn_assistant_tokens_mask==True but chat template does not contain `\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;132;01m% g\u001B[39;00m\u001B[38;5;124meneration \u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m}` keyword.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1814\u001B[0m     )\n",
      "File \u001B[0;32m~/projects/llm_study/venvs/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1970\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.get_chat_template\u001B[0;34m(self, chat_template, tools)\u001B[0m\n\u001B[1;32m   1968\u001B[0m         chat_template \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchat_template\n\u001B[1;32m   1969\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1970\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1971\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot use chat template functions because tokenizer.chat_template is not set and no template \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1972\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124margument was passed! For information about writing templates and setting the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1973\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtokenizer.chat_template attribute, please see the documentation at \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1974\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://huggingface.co/docs/transformers/main/en/chat_templating\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1975\u001B[0m         )\n\u001B[1;32m   1977\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m chat_template\n",
      "\u001B[0;31mValueError\u001B[0m: Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cfdd6b80ac0eeaed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
